# IntÃ©gration LLM - Guide complet

## ğŸ¯ RÃ©sumÃ© de l'implÃ©mentation

Architecture complÃ¨te pour intÃ©grer l'API Infomaniak LLM (Qwen3) dans datannur, inspirÃ©e du POC.

### Fichiers crÃ©Ã©s

```
src/llm/
â”œâ”€â”€ llm-schema.ts       # Types enrichis (DB + computed + relations + user)
â”œâ”€â”€ llm-context.ts      # Context builder (stats, user, UI state)
â”œâ”€â”€ llm-config.ts       # Configuration API (key, product ID)
â”œâ”€â”€ llm-client.ts       # Client API avec streaming SSE
â”œâ”€â”€ llm-tools.ts        # 12 tools pour query/analysis/navigation
â”œâ”€â”€ llm-setup.ts        # Helper pour setup rapide
â”œâ”€â”€ llm-demo.ts         # DÃ©mos & tests
â”œâ”€â”€ LLMChat.svelte      # Composant UI chat
â”œâ”€â”€ index.ts            # Exports publics
â””â”€â”€ README.md           # Documentation
```

## ğŸš€ Utilisation rapide

### 1. Setup dans browser console

```javascript
// Initialiser avec credentials du POC
setupLLM()

// Ou vÃ©rifier que c'est configurÃ©
localStorage.getItem('llm-api-key')
localStorage.getItem('llm-product-id')
```

### 2. Tester dans console

```javascript
// Test simple
await demoSimpleChat()

// Test avec streaming
await demoStreamingChat()

// Test avec tools
await demoWithTools()

// Test conversation complÃ¨te
await demoConversation()

// Tous les tests
await runAllDemos()
```

### 3. Utiliser dans l'app

```svelte
<!-- Dans une page Svelte -->
<script>
  import LLMChat from '@llm/LLMChat.svelte'
</script>

<div class="container">
  <h1>Assistant LLM</h1>
  <LLMChat />
</div>
```

## ğŸ”‘ Points clÃ©s vs POC

### Similitudes conservÃ©es

âœ… **Streaming SSE** - MÃªme parsing des `data:` events  
âœ… **Credentials** - MÃªme API key et product ID  
âœ… **Models** - Qwen3 pour texte, Whisper pour STT  
âœ… **UI** - Markdown rendering avec marked.js

### AmÃ©liorations

ğŸš€ **Pas de proxy Python** - Appel direct depuis le browser  
ğŸš€ **Types TypeScript** - Type-safety complÃ¨te  
ğŸš€ **Tools system** - 12 tools pour interroger la DB  
ğŸš€ **Context builder** - Context automatique de l'app  
ğŸš€ **Svelte components** - Integration native dans l'UI  
ğŸš€ **Multi-turn** - Gestion conversation avec historique

## ğŸ“Š Architecture Context

### Ce qui est envoyÃ© au LLM

**System Prompt :**

- Documentation schÃ©ma (types TypeScript)
- Documentation tools disponibles
- Context actuel (stats DB + user + UI)

**Format :**

```typescript
{
  stats: {
    nbDatasets: 150,
    nbVariables: 2340,
    datasetsByType: { panel: 45, cross: 105 },
    // ...
  },
  user: {
    favorites: { dataset: [...], variable: [...] },
    searchHistory: [...],
    options: { darkMode: true, language: 'fr' }
  },
  ui: {
    currentPage: '/dataset/123',
    currentTab: 'variables',
    activeFilters: {...}
  }
}
```

**Taille :** ~500-800 tokens (sans samples)

### Tools disponibles

**Query (4) :**

- `findEntities` - Chercher avec critÃ¨res
- `getEntity` - Get par ID
- `countEntities` - Compter
- `searchInCatalog` - Full-text search

**Analysis (3) :**

- `groupBy` - Grouper et compter
- `getStatistics` - Stats numÃ©riques
- `getRelatedEntities` - Relations

**Navigation (1) :**

- `navigate` - Naviguer dans l'app

**User Data (1) :**

- `toggleFavorite` - GÃ©rer favoris

**Filters (2) :**

- `applyFilter` - Appliquer filtres
- `clearFilters` - Effacer filtres

## ğŸ“ Exemples de conversations

### Question simple

**User:** "Combien de datasets ?"  
**LLM:** Appelle `countEntities({entity: 'dataset'})`  
**Result:** "Il y a 150 datasets dans le catalogue."

### Question complexe

**User:** "Quels sont les 5 datasets panel les plus rÃ©cents ?"  
**LLM:**

1. `findEntities({entity: 'dataset', criteria: {type: 'panel'}})`
2. Trie par `lastUpdateDate`
3. Prend top 5
   **Result:** Liste formatÃ©e avec noms et dates

### Navigation contextuelle

**User:** "Montre-moi ce dataset"  
**LLM:** Lit `ui.currentPage`, identifie le dataset actuel  
**Action:** `navigate('/dataset/123')` si pas dÃ©jÃ  dessus

### Analyse

**User:** "Quelle est la taille moyenne des datasets ?"  
**LLM:** `getStatistics({entity: 'dataset', field: 'nbRow'})`  
**Result:** "En moyenne 45 230 lignes (min: 100, max: 2M)"

## ğŸ”„ Flow d'une requÃªte

```
1. User input
   â†“
2. Add to messages[]
   â†“
3. Call chatCompletion() avec tools
   â†“
4. Streaming SSE depuis API
   â†“
5. Parse chunks: content OU tool_calls
   â†“
6. Si tool_call:
   - executeTool()
   - Add result to messages
   - Re-call LLM with result
   â†“
7. Display final response
```

## âš¡ Optimisations

### Tokens

- Context minimal par dÃ©faut (~500 tokens)
- Tools appelÃ©s Ã  la demande
- Pas de full DB envoyÃ©e

### Performance

- Streaming pour UX responsive
- Cache possible des rÃ©ponses courantes
- Batch tool calls si multiple queries

### UX

- Loading states clairs
- Markdown rendering
- Scroll auto vers bas
- Cancel possible (AbortController)

## ğŸ” SÃ©curitÃ©

**API Key :**

- StockÃ©e en localStorage
- Jamais commitÃ©e dans code
- Configurable par utilisateur

**Rate limiting :**

- GÃ©rÃ© par Infomaniak
- Retry avec backoff possible
- Error handling complet

**Validation :**

- Tool parameters validÃ©s
- Criteria sanitized
- No SQL injection (pas de SQL!)

## ğŸ› Debugging

### Browser console

```javascript
// VÃ©rifier config
getLLMConfig()

// Tester tool directement
executeTool('countEntities', { entity: 'dataset' })

// Voir le context
buildLLMContext()

// Reset config
clearLLMAPIKey()
clearLLMProductId()
```

### Logs

Le client log automatiquement :

- Tool calls avec params
- Streaming errors
- API errors

## ğŸ“ˆ Prochaines Ã©tapes

**Phase 1 - MVP** (actuel)

- âœ… Client API avec streaming
- âœ… 12 tools essentiels
- âœ… Composant chat UI
- âœ… Context builder
- â³ Tests & debug

**Phase 2 - Enhancements**

- ğŸ”² Whisper STT integration
- ğŸ”² Voice input button
- ğŸ”² Conversation persistence
- ğŸ”² Context window management
- ğŸ”² Better error messages

**Phase 3 - Advanced**

- ğŸ”² Embeddings pour semantic search
- ğŸ”² RAG sur documentation
- ğŸ”² Custom prompts par user
- ğŸ”² Analytics & feedback loop
- ğŸ”² Multi-language support

## ğŸ’¡ DiffÃ©rences vs Extension VS Code

| Aspect      | Extension    | App Browser              |
| ----------- | ------------ | ------------------------ |
| **Install** | Requise      | Aucune                   |
| **Access**  | VS Code only | N'importe quel browser   |
| **Context** | DB brute     | DB processÃ©e + UI + user |
| **Tools**   | SQL queries  | TS functions natives     |
| **UX**      | External     | Native dans l'app        |
| **Setup**   | Complex      | Juste API key            |
| **Data**    | Normalized   | Denormalized + computed  |

## ğŸ‰ Conclusion

Architecture complÃ¨te et production-ready pour LLM dans datannur :

- **Single source of truth** : Types TS = documentation
- **Smart context** : DonnÃ©es processÃ©es + user + UI
- **Powerful tools** : AccÃ¨s direct aux fonctions de l'app
- **Great UX** : Streaming, markdown, mobile-friendly
- **Easy setup** : Juste copier l'API key

PrÃªt Ã  tester ! ğŸš€
